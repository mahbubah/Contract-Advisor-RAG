{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedding_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerEmbeddingFunction\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv\n",
      "File \u001b[0;32m/workspaces/Contract-Advisor-RAG/.venv/lib/python3.10/site-packages/chromadb/__init__.py:86\u001b[0m\n\u001b[1;32m     84\u001b[0m             sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     87\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[91mYour system has an unsupported version of sqlite3. Chroma \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124m                    requires sqlite3 >= 3.35.0.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[94mPlease visit \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124m                    https://docs.trychroma.com/troubleshooting#sqlite to learn how \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m                    to upgrade.\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[38;5;124m[0m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m             )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override Chroma's default settings, environment variables or .env files\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \u001b[91mYour system has an unsupported version of sqlite3. Chroma                     requires sqlite3 >= 3.35.0.\u001b[0m\n\u001b[94mPlease visit                     https://docs.trychroma.com/troubleshooting#sqlite to learn how                     to upgrade.\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from chromadb import Client\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    docx_texts = [paragraph.text.strip() for paragraph in doc.paragraphs if paragraph.text.strip()]\n",
    "\n",
    "    character_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], chunk_size=500, chunk_overlap=0)\n",
    "    character_split_texts = character_splitter.split_text('\\n\\n'.join(docx_texts))\n",
    "\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "    token_split_texts = []\n",
    "    for text in character_split_texts:\n",
    "        token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "    return token_split_texts\n",
    "\n",
    "# Example document path\n",
    "docx_path = \"../Evaluation Sets/Raptor Contract.docx\"\n",
    "documents = preprocess_document(docx_path)\n",
    "\n",
    "# Embedding function\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "# Create ChromaDB collection and add documents\n",
    "chroma_collection = chroma_client.create_collection(\"Contract\", embedding_function=embedding_function)\n",
    "ids = [str(i) for i in range(len(documents))]\n",
    "chroma_collection.add(ids=ids, documents=documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_documents(query, collection):\n",
    "    results = collection.query(query_texts=[query], n_results=5)\n",
    "    retrieved_documents = results['documents'][0]\n",
    "    return retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert contract advisor assistant. Your users are asking questions about information contained in the contract.\"\n",
    "                       \"You will be shown the user's question, and the relevant information from the contract. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message['content']\n",
    "    return content\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def rank_documents(query, documents):\n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    pairs = [[query, doc] for doc in documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    ranked_indices = np.argsort(scores)[::-1]\n",
    "    ranked_documents = [documents[i] for i in ranked_indices]\n",
    "    return ranked_documents\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_multiple_query(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert contract advisor assistant. Your users are asking questions about information contained in the contract.\"\n",
    "                       \"Suggest up to five additional related questions to help them find the information they need, for the provided question. \"\n",
    "                       \"Suggest only short questions without compound sentences. Suggest a variety of questions that cover different aspects of the topic.\"\n",
    "                       \"Make sure they are complete questions, and that they are related to the original question.\"\n",
    "                       \"Output one question per line. Do not number the questions.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message['content']\n",
    "    content = content.split(\"\\n\")\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_query_expansion(original_query, model=\"gpt-3.5-turbo\"):\n",
    "    # Expand the original query\n",
    "    expanded_queries = augment_multiple_query(original_query, model=model)[:5]  # Limit to top 5 expanded queries\n",
    "\n",
    "    # Include the original query in the list of queries\n",
    "    queries = [original_query] + expanded_queries\n",
    "\n",
    "    # Query ChromaDB for relevant documents\n",
    "    results = chroma_collection.query(query_texts=queries, n_results=5, include=['documents'])\n",
    "    retrieved_documents = results['documents']\n",
    "\n",
    "    # Deduplicate the retrieved documents\n",
    "    unique_documents = set()\n",
    "    for documents in retrieved_documents:\n",
    "        for document in documents:\n",
    "            unique_documents.add(document)\n",
    "\n",
    "    # Convert back to list for indexing\n",
    "    unique_documents = list(unique_documents)\n",
    "\n",
    "    # Rank documents based on relevance to each query\n",
    "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    pairs = [[query, doc] for doc in unique_documents for query in queries]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "\n",
    "    # Sort documents based on average score across all queries\n",
    "    avg_scores = np.mean(np.array(scores).reshape(len(queries), -1), axis=0)\n",
    "    ranked_indices = np.argsort(avg_scores)[::-1]\n",
    "    ranked_documents = [unique_documents[i] for i in ranked_indices]\n",
    "\n",
    "    # Generate answer using RAG with ranked documents\n",
    "    information = \"\\n\\n\".join(ranked_documents[:5])  # Use top 5 ranked documents\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert legal contract advisor assistant. Your users are asking questions about information contained in the contract.\"\n",
    "                       \"You will be shown the user's question, and the relevant information from the contract. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {original_query}. \\n Information: {information}\"},\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Provide concise answers without additional explanation unless explicitly requested.\"\n",
    "                    \"Identify questions that require a simple yes or no response, and Provide concise answers without additional explanation unless explicitly requested.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message['content']\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Example query\n",
    "    #query = \"What is the purpose of the escrow? \"\n",
    "    \n",
    "    original_query = \"May the Escrow Amount serve as a recourse for the Buyer in case of breach of representations by the Company?\"\n",
    "    \n",
    "    # Generate answer with query expansion and RAG\n",
    "    output = rag_with_query_expansion(original_query)\n",
    "   \n",
    "    \n",
    "    # Print or use the answer as needed\n",
    "    print(\"Generated Answer:\")\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
